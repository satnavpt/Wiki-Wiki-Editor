{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Fake News Detector",
      "provenance": [],
      "mount_file_id": "1DS3NkhS6mw07QQHZBBlO1F7tx_aQh1dA",
      "authorship_tag": "ABX9TyMdWfjjrxA0sRRKEVPfFPWL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satnavpt/Wiki-Wiki-Editor/blob/master/DataSamples/Fake_News_Stage/Main_Fake_News_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Imports`**"
      ],
      "metadata": {
        "id": "jZucprNInWap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THLV2WS2NEh",
        "outputId": "17da3adf-3540-47ac-876e-f21424d24f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Bidirectional\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Data Preprocessing`**"
      ],
      "metadata": {
        "id": "0xtTlQ-nnQzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Fake News Stage/UTK_train.csv')\n",
        "df = df.dropna()\n",
        "text = df.text.apply(lambda x: (re.sub(r'[^\\w ]+', \"\", x).lower()))\n",
        "#Remove punctuation from the input. Numbers are kept as they may be facts that would help indicate whether a sentence contains fake news. \n",
        "#Implicit preprocessing is also completed via one_hot. \n",
        "label = df.label.tolist()"
      ],
      "metadata": {
        "id": "3vIIeQga2cCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 200000 # Vocabulary size - the number of possible distinct words used in this ML model.\n",
        "#According to the Oxford English Dictionary, there are an estimated 171,146 words currently in use in the English language.\n",
        "#A buffer size has been added as new words / abbreviations / slang may be added to Wikipedia articles as time progresses. \n",
        "#In addition, having a vocab size that's larger than the true vocab size increases the uniqueness of the hashes completed by one_hot, for more accurate results. \n",
        "\n",
        "one_hot_representation = [one_hot(sentences, voc_size) for sentences in text] \n",
        "#Converts each word into a unique numerical represenation as the ML model used only operates on numerics.\n",
        "#It also split words based on white space.\n",
        "\n",
        "sentence_len = 30 \n",
        "#The average sentence size in English is 15 - 20 words, so this is a conservative number to limit the amount of information loss from longer senetences whilst also\n",
        "#ensuring that excessive padding isn't applied to each sentence. \n",
        "embedded_sentence = pad_sequences(one_hot_representation, padding = 'post', maxlen = sentence_len)\n",
        "#This padds (adds 0s to) a sentence's one-hot if the sentence is under sentence_len words\n",
        "#and truncates the one-hot of sentences over sentence_len words to ensure that every sentence's representation is the same shape. \n",
        "#This is necessary as LSTM operates on fixed-size data points. \n",
        "#post padding is used so neural network training is efficient. "
      ],
      "metadata": {
        "id": "n_DIqTrN3dLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`LSTM Model`**"
      ],
      "metadata": {
        "id": "kF-BP42kndsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model = Sequential([\n",
        "#A sequential model allows the model to be created layer-by-layer. Its input is an embedded sentence (of size sentence_len) and its output is a 0 - 1 float. \n",
        "                    Embedding(input_dim = (voc_size + 1), output_dim = 100, input_length = sentence_len, mask_zero = True),\n",
        "#Create a 2D vector containing an embedding vector of size 100 for each word's one-hot.\n",
        "#Embedding vector -  Encodes the meaning of a word such that words that are closer together in the learned vector space are expected to be simmilar in meaning.\n",
        "#(voc_size + 1) as the padding value 0 is masked out.\n",
        "                    Dropout(0.1, noise_shape = None, seed = None),\n",
        "#Randomly set input units to 0 with a frequency of 0.1 and recale up the rest such that the sum over all inputs is unchanged. This helps prevent overfitting. \n",
        "                    MaxPooling1D(pool_size = 3, strides = 3, padding = 'same', data_format = 'channels_last'),\n",
        "#Iterates over the inputs and takes the highest value, which compresses the feature space whilst retaining the important features. \n",
        "                    Bidirectional(LSTM(100, activation = 'tanh', use_bias = 'true', kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', bias_initializer = 'zeros',\n",
        "                                       unit_forget_bias = True), merge_mode = 'concat'),\n",
        "#LSTM is a RNN that's effective in making predictions for long sequences of data such as sentences as it uses a memory cell to withhold past infromation for a longer time.\n",
        "#tanh is used as it's second derivative can sustain for a long range before going to zero, which helps to overcome the vanishing gradient problem.                       \n",
        "                    Dropout(0.1, noise_shape = None, seed = None),\n",
        "                    Dense(1, activation = 'sigmoid', use_bias = True, kernel_initializer = 'glorot_uniform')\n",
        "#Dense feeds all outputs from the previous layer to all of its neurons, with each neuron providing one output (a misinformation prediction) via matrix-vector multiplication. \n",
        "                  ])\n",
        "misinformation_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "print(misinformation_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_EOmcC74DRL",
        "outputId": "93ffa4fa-ab0b-4055-d4d1-07f08b30373e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 30, 100)           20000100  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 100)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 100)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 200)              160800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,161,101\n",
            "Trainable params: 20,161,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_valid, label_train, label_valid = train_test_split(embedded_sentence, df['label'], test_size = 0.2, random_state = 42)\n",
        "#random_state is used for reproducible output across multiple function calls to allow the model to be fine_tuned"
      ],
      "metadata": {
        "id": "Q8qm75Uo5W31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model.fit(data_train, label_train, epochs = 3)"
      ],
      "metadata": {
        "id": "Kr3b2Pho5kFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd2404f-b428-423f-e2b5-05c60256a6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "458/458 [==============================] - 12s 17ms/step - loss: 0.3728 - acc: 0.8134\n",
            "Epoch 2/3\n",
            "458/458 [==============================] - 8s 17ms/step - loss: 0.1220 - acc: 0.9537\n",
            "Epoch 3/3\n",
            "458/458 [==============================] - 8s 17ms/step - loss: 0.0248 - acc: 0.9918\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2999714a50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model.save('A_misinformation_model_LSTM.h5') #Creates a HDF5 file for the model. \n",
        "with open(\"A_one_hot_encoder\", \"wb\") as f: \n",
        "    pickle.dump(one_hot, f)"
      ],
      "metadata": {
        "id": "6HBfL52PTNLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Model Evaluation & Testing`**"
      ],
      "metadata": {
        "id": "axdkzLlTTBFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = (misinformation_model.predict(data_valid) >= 0.5).astype(int)\n",
        "accuracy_score(label_valid, test_pred, normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgA3LH1RYr5w",
        "outputId": "ca6a05d6-1fac-4c44-b181-fe3bbeed66cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8640962537599125"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_data = pd.read_csv('UTK_test.csv')\n",
        "df_test_label = pd.read_csv('UTK_submit.csv')\n",
        "df_test = pd.merge(df_test_data, df_test_label)\n",
        "df_test = df_test.dropna()\n",
        "test_text = df_test.text.apply(lambda x: (re.sub(r'[^\\w ]+', \"\", x).lower()))\n",
        "test_one_hot_representation = [one_hot(sentences, voc_size) for sentences in test_text] \n",
        "test_embedded_sentence = pad_sequences(test_one_hot_representation, padding = 'post', maxlen = sentence_len)\n",
        "test_label = df_test.label.tolist()\n",
        "test_pred = (misinformation_model.predict(test_embedded_sentence) >= 0.5).astype(int)\n",
        "accuracy_score(test_label, test_pred, normalize = True)"
      ],
      "metadata": {
        "id": "QnZGTKdf9inM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Model Use`**"
      ],
      "metadata": {
        "id": "fqthJi9J2qZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#misinformation_model = load_model('/content/drive/MyDrive/Fake News Stage/misinformation_model_LSTM.h5')\n",
        "#with open(\"/content/drive/MyDrive/Fake News Stage/one_hot_encoder\", \"rb\") as f: \n",
        "#  one_hot = pickle.load(f)\n",
        "\n",
        "def fake_news_detection(data): \n",
        "  detect_sentences = 5 #Maximum number of detections given to the user.  \n",
        "  words_to_show = 8 #The length of the sentence snippet shown of a detected sentence.  \n",
        "  sentences = np.asarray(sent_tokenize(data)) #Split data into sentences. \n",
        "  one_hot_representations = [one_hot(s, 200000) for s in sentences] \n",
        "  #Splits up the words in each sentence and converts them into a unique numerical representation \n",
        "  #as the ML model used only operates on numerics. (voc_size = 200000)\n",
        "  embedded_sentences = pad_sequences(one_hot_representations, padding = 'post', maxlen = 30)\n",
        "  #Padds or truncates a sentence's one-hot to a length of 30 as the LSTM model created operates on fixed-size data points.\n",
        "  predictions = np.concatenate(np.asarray(misinformation_model.predict(embedded_sentences)), axis = 0)\n",
        "  print(predictions)\n",
        "  #Make a misinformation prediction for each sentence and then combine these into an numpy array.\n",
        "  detect_sent_index = np.argsort(predictions)[:detect_sentences] #Indicies\n",
        "  #The sentences selected for detection are those which, according to the model, are most likely to relate to misinfotmation. \n",
        "  to_delete = []\n",
        "  for i in range (0, len(detect_sent_index)): \n",
        "    if predictions[detect_sent_index[i]] >= 0.5: #Check whether the detected sentences should actually be flagged (i.e. if they appear to contain misinformation)\n",
        "      to_delete.append(i)\n",
        "  detect_sent_index = np.delete(detect_sent_index, to_delete) #Don't flag any sentences which aren't expected to contain misinformation. \n",
        "  detected = np.take(sentences, detect_sent_index) #Find the sentences that relate to the flagged misinformation predictions. \n",
        "  detected = [((\" \".join(s.split()[:words_to_show])) + \" ...\") for s in detected] #Truncate the detected sentences for ease of printing.\n",
        "  if len(detected) == 0:\n",
        "    detected_message = [\"No sentences were flagged for misinformation.\"]\n",
        "  else:\n",
        "    detected_message = [\"These sentences may contain misinformation: \"]\n",
        "    for i in range(0, len(detected)):\n",
        "      detected_message.append(str(i + 1) + \". \" + str(detected[i]))\n",
        "  return detected_message #An array of sentences to be displayed to the user in the GUI. "
      ],
      "metadata": {
        "id": "kOdPKUR2B--a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Fake News Stage/DonaldTrumpWiki.txt', 'r') as file:\n",
        "    trump = file.read().replace('\\n', '')\n",
        "with open('/content/drive/MyDrive/Fake News Stage/SwimmingWiki.txt', 'r') as file:\n",
        "    swimming = file.read().replace('\\n', '')\n",
        "result = fake_news_detection(trump)\n",
        "\n",
        "for r in result:\n",
        "  print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1VQ54S8V463",
        "outputId": "c16abacc-83ce-4d8f-dc51-77fade3bfcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.3378730e-01 9.9656481e-01 9.9276853e-01 9.9582052e-01 9.9909031e-01\n",
            " 9.9317354e-01 9.9739122e-01 9.9395221e-01 3.3969182e-01 7.7444690e-01\n",
            " 9.9929321e-01 9.9970764e-01 9.9729949e-01 8.4798532e-03 3.6933671e-03\n",
            " 9.9045300e-01 9.9766880e-01 9.0404898e-01 9.9318659e-01 9.3541521e-01\n",
            " 4.0104854e-01 9.9917042e-01 2.3149853e-03 9.7054601e-02 9.9966490e-01\n",
            " 9.9351925e-01 9.9803156e-01 9.9117237e-01 9.8685962e-01 9.9853611e-01\n",
            " 4.9285913e-01 5.9289020e-04 9.5893008e-01 5.1912802e-01 8.8985521e-01\n",
            " 9.9958938e-01 8.1314898e-01 4.6740076e-01 9.9938917e-01 9.9996471e-01\n",
            " 9.9724233e-01 9.9927324e-01 9.9945182e-01 9.9928325e-01 9.9823028e-01\n",
            " 9.9816680e-01 9.9900371e-01 9.7988164e-01 9.9818724e-01 9.6669233e-01\n",
            " 9.9856359e-01 9.9781358e-01 9.9898964e-01 9.9638593e-01 9.8573500e-01\n",
            " 9.7522449e-01 9.9519497e-01 9.9413484e-01 9.9909043e-01 4.9845962e-04\n",
            " 9.7210914e-01 9.9921072e-01 9.9770385e-01 9.9938464e-01 9.9929345e-01\n",
            " 9.9127394e-01 9.9849677e-01 9.9623680e-01 9.9924386e-01 9.8318845e-01\n",
            " 9.2904764e-01 9.7888386e-01 2.2336228e-04 2.3254313e-02 9.1107589e-01\n",
            " 9.9847251e-01 1.8384176e-01 9.9715865e-01 9.9725586e-01 9.8171622e-01\n",
            " 9.9554729e-01 9.9413234e-01 9.9698997e-01 8.9058095e-01 7.6772473e-03\n",
            " 9.9920315e-01 9.9931324e-01 9.8699152e-01 9.9543023e-01 6.3087630e-01\n",
            " 9.7671938e-01 3.2286802e-01 9.8900032e-01 8.9411277e-01 9.9827230e-01\n",
            " 9.9546140e-01 9.9901056e-01 9.9924266e-01 9.9878556e-01 5.7032633e-01\n",
            " 8.4598243e-01 9.9843758e-01 9.9447048e-01 9.9679178e-01 9.9267018e-01\n",
            " 9.7731632e-01 9.9990773e-01 9.9675167e-01 9.9758673e-01 9.9803275e-01\n",
            " 9.9918228e-01 9.4979882e-01 9.9632686e-01 9.8900056e-01 5.5126935e-01\n",
            " 9.9943358e-01 9.9100387e-01 9.9670368e-01 9.9771225e-01 9.9759549e-01\n",
            " 2.4984515e-01 9.9973184e-01 9.7651199e-02 9.9606353e-01 9.9243236e-01\n",
            " 7.7721081e-04 7.2896504e-01 2.9323017e-03 9.9930036e-01 9.9865270e-01\n",
            " 3.7038871e-03 5.3982371e-03 9.9938440e-01 9.9164647e-01 9.5475125e-01\n",
            " 9.9877161e-01 9.8576272e-01 9.9995327e-01 9.9149573e-01 9.9895704e-01\n",
            " 1.0281458e-02 1.2030158e-01 9.3057048e-01 9.9944431e-01 9.2430317e-01\n",
            " 9.9528766e-01 9.9973947e-01 9.9175406e-01 9.9793267e-01 8.6044121e-01\n",
            " 1.9583877e-04 9.9914050e-01 8.0030318e-04 9.9333221e-01 1.1127725e-02\n",
            " 9.8667890e-01 9.9945503e-01 9.7983092e-01 9.9922359e-01 2.4771632e-04\n",
            " 9.9885452e-01 2.0496486e-02 9.4338143e-01 9.9972850e-01 1.3750323e-02\n",
            " 8.3632100e-01 1.4520009e-01 9.9352175e-01 5.3287562e-02 5.4376733e-02\n",
            " 9.9975044e-01 9.8204494e-01 9.9986506e-01 9.9247885e-01 9.9927860e-01\n",
            " 9.9483454e-01 9.9736649e-01 9.9792105e-01 9.9305421e-01 9.9747294e-01\n",
            " 9.9738735e-01 9.9959415e-01 8.4789836e-01 5.1831603e-01 9.8882592e-01\n",
            " 9.9538797e-01 2.2023542e-04 9.9713719e-01 9.9771309e-01 4.0893045e-01\n",
            " 9.9929690e-01 9.9895406e-01 8.8802260e-01 9.9795949e-01 4.6474659e-01\n",
            " 9.9372876e-01 9.9907124e-01 9.9608046e-01 9.9503195e-01 9.9757451e-01\n",
            " 9.9970740e-01 9.9806041e-01 9.9591714e-01 9.9772924e-01 9.9490106e-01\n",
            " 9.9580413e-01 9.9924374e-01 8.1382620e-01 9.9988902e-01 9.9786770e-01\n",
            " 9.9838006e-01 2.3887863e-02 9.9971718e-01 5.4735261e-01 9.9864644e-01\n",
            " 2.9711497e-03 2.4376544e-03 6.4485079e-01 3.8636088e-01 9.9759322e-01\n",
            " 9.9335629e-01 9.9770194e-01 9.3251187e-01 9.9475348e-01 7.8644311e-01\n",
            " 9.8162514e-01 1.1503186e-02 9.5301765e-01 5.4790169e-01 9.9983191e-01\n",
            " 9.8505706e-01 9.9674404e-01 9.9354172e-01 9.9845743e-01 9.9893183e-01\n",
            " 6.8792915e-01 9.9853587e-01 9.9776983e-01 9.9517304e-01 9.9261659e-01\n",
            " 9.9870574e-01 5.6256950e-01 8.5664350e-01 9.8037225e-01 1.2212659e-02\n",
            " 9.9499005e-01 9.9420643e-01 9.9958199e-01 7.8969300e-01 5.7106115e-02\n",
            " 9.9815995e-01 9.9627125e-01 9.7982931e-01 9.5124370e-01 9.8073441e-01\n",
            " 9.9977916e-01 1.4688720e-05 9.2728710e-01 9.9859780e-01 6.0358495e-01\n",
            " 9.9801672e-01 9.5055288e-01 9.9008673e-01 9.9637836e-01 9.9912184e-01\n",
            " 9.8337018e-01 4.0003299e-05 9.8722470e-01 9.7832125e-01 9.9893790e-01\n",
            " 6.1591956e-05 8.0540603e-01 9.9941516e-01 9.9831355e-01 3.5640842e-01\n",
            " 9.8844761e-01 2.8434624e-05 9.9823773e-01 3.4954704e-04 2.1416474e-02\n",
            " 1.0217191e-02 9.9907720e-01 6.6890981e-04 9.9397945e-01 8.0613035e-01\n",
            " 9.8173118e-01 8.5987002e-02 9.9575752e-01 9.7562784e-01 9.8952651e-01\n",
            " 9.1598362e-01 8.8860828e-01 9.9928540e-01 4.5566055e-01 1.3525672e-01\n",
            " 9.7802198e-01 9.9797386e-01 7.6258159e-01 2.3663670e-01 9.1752577e-01\n",
            " 6.1077458e-01 9.1758353e-01 4.6924996e-04 6.4806495e-04 9.9116033e-01\n",
            " 8.6002457e-01 1.3211210e-02 9.9430895e-01 9.0300339e-01 9.8766440e-01\n",
            " 1.3493285e-01 2.0268293e-02 6.2131405e-01 9.9245489e-01 5.4713450e-07\n",
            " 9.8815674e-01 9.9170601e-01 9.9541581e-01 2.1521848e-02 9.9888164e-01\n",
            " 9.9943954e-01 9.9748814e-01 9.5401347e-01 8.9825699e-05 9.8798603e-01\n",
            " 5.2969652e-05 5.5456632e-03 5.7720780e-01 9.5835078e-01 9.9357879e-01\n",
            " 9.6062195e-01 9.9651092e-01 9.9915016e-01 3.2538618e-04 7.2510773e-03\n",
            " 9.9748385e-01 5.4156268e-01 3.2219358e-02 1.6007787e-02 9.3927008e-01\n",
            " 9.7746640e-01 9.9710828e-01 9.9417043e-01 2.6879936e-01 9.8043472e-01\n",
            " 9.8125446e-01 9.9139261e-01 9.9747258e-01 9.9884951e-01 9.9842298e-01\n",
            " 4.2292198e-05 4.0445724e-03 9.9821943e-01 2.0625348e-06 1.1745594e-04\n",
            " 9.9561042e-01 7.6646596e-01 9.9387497e-01 9.4848925e-01 9.6927524e-01\n",
            " 1.2960869e-01 6.0576916e-02 1.9414066e-03 9.9776566e-01 3.1013288e-02\n",
            " 2.5456873e-06 3.3588207e-05 3.3676475e-05 1.9883779e-03 8.3797842e-01\n",
            " 1.3403203e-01 9.9554694e-01 9.6240038e-01 6.1131973e-06 6.6629863e-01\n",
            " 2.9012701e-03 9.9964631e-01 5.5893685e-04 9.9767250e-01 3.2534050e-03\n",
            " 9.9972457e-01 2.7685513e-05 8.1325543e-01 9.6983451e-01 9.5823556e-01\n",
            " 9.6560574e-01 2.2471301e-01 9.7894365e-01 9.9991870e-01 9.9387121e-01\n",
            " 9.9774230e-01 4.6682602e-01 9.9551648e-01 9.9432981e-01 9.2491858e-02\n",
            " 9.8869574e-01 9.9209291e-01 9.8232102e-01 6.3578761e-01 9.9389356e-01\n",
            " 9.9895525e-01 9.9939072e-01 9.9821669e-01 9.9834621e-01 9.8992693e-01\n",
            " 9.9845672e-01 9.9474561e-01 9.9834847e-01 9.6009046e-01 9.7736281e-01\n",
            " 8.1053030e-01 3.4104060e-02 9.8613805e-01 9.9697495e-01 9.9898285e-01\n",
            " 9.8484761e-01 8.4719958e-04 9.9949563e-01 9.9870503e-01 9.2242879e-01\n",
            " 9.9699968e-01 9.9492055e-01 9.9065393e-01 4.9892645e-03 3.2776859e-02\n",
            " 3.1711742e-02 9.5811510e-01 9.9554658e-01 9.8903799e-01 9.9379373e-01\n",
            " 6.7652538e-03 9.9754602e-01 9.6741909e-01 9.7252077e-01 9.9909806e-01\n",
            " 8.8905156e-01 9.9901116e-01 9.9952471e-01 5.2578687e-03 9.8619938e-01\n",
            " 9.9944729e-01 3.5297837e-02 9.9948031e-01 9.6668845e-01 8.5431840e-03\n",
            " 2.7042762e-03 9.9168992e-01 8.1655753e-01 9.8930675e-01 9.9888796e-01\n",
            " 2.2333650e-02 9.7382247e-01 3.2581691e-02 9.9346113e-01 1.9120039e-02\n",
            " 9.8610431e-01 3.3248481e-01 9.2640549e-01 6.8609728e-03 8.8698370e-03\n",
            " 8.1999805e-03 2.9821450e-01 9.9328035e-01 9.9351197e-01 3.8123410e-02\n",
            " 9.8936999e-01 2.7039084e-01 9.9554777e-01 9.9847788e-01 9.9811447e-01\n",
            " 9.9743903e-01 8.4090934e-05 1.3008390e-01 9.0812236e-01 9.6108055e-01\n",
            " 8.9355104e-02 1.9024593e-01 9.9509853e-01 9.9402702e-01 9.2613095e-01\n",
            " 2.0672113e-01 9.9862361e-01 8.1324238e-01 8.9362538e-01 9.9944347e-01\n",
            " 9.8148268e-01 9.9719030e-01 9.9732554e-01 9.9910909e-01 9.9479055e-01\n",
            " 9.9527043e-01 9.9987578e-01 9.9981278e-01 3.6627170e-01 7.9174883e-05\n",
            " 4.2787486e-01 9.8505276e-01 9.9997354e-01 7.8309816e-01 9.9842656e-01\n",
            " 9.9654120e-01 9.9895716e-01 9.9987054e-01 7.1367577e-02 9.8285854e-01\n",
            " 9.9774867e-01 1.7288814e-01 9.9751902e-01 9.9982399e-01 9.9874288e-01\n",
            " 9.9865180e-01 9.8650813e-01 2.0424633e-03 9.8537934e-01 9.9996710e-01\n",
            " 9.9973303e-01 9.9588472e-01 9.9985445e-01 9.9887949e-01 4.3726649e-02\n",
            " 6.3533103e-01 9.9766940e-01 9.9832255e-01 9.9892801e-01 9.5722413e-01\n",
            " 9.1761875e-01 9.9046248e-01 9.9930227e-01 9.9708527e-01 9.9683052e-01\n",
            " 9.8440582e-01 9.9975091e-01 9.9794143e-01 9.5695651e-01 5.7438070e-01\n",
            " 2.4664655e-02 9.9792129e-01 9.9978942e-01 9.9977535e-01 9.9494088e-01\n",
            " 9.9670792e-01 8.5213041e-01 9.9974877e-01 9.9029118e-01 9.9537104e-01\n",
            " 3.3810735e-01 9.9941432e-01 9.9856323e-01 1.7089443e-01 9.4356614e-01\n",
            " 2.2143921e-01 3.8047177e-01 4.5945656e-02 5.8985311e-01 9.9944264e-01\n",
            " 9.8526913e-01 2.6334405e-01 9.4752043e-01 2.7208472e-02 1.8434605e-02\n",
            " 1.5196112e-02 9.9256563e-01 9.9547887e-01 9.9272138e-01 9.9729460e-01\n",
            " 9.9784338e-01 9.9934822e-01 9.4869095e-01 9.9853492e-01 9.9972111e-01\n",
            " 9.9908304e-01 9.9593413e-01 9.9892908e-01 1.0752657e-02 9.3321872e-01\n",
            " 9.9941921e-01 9.9884903e-01 7.9081035e-01 9.8661751e-01 9.9974257e-01\n",
            " 1.4190283e-01 9.9903309e-01 9.9977022e-01 2.5807617e-03 9.9955982e-01\n",
            " 9.9388820e-01 8.3708614e-02 9.9887854e-01 9.9588984e-01 5.6602371e-01\n",
            " 9.9863237e-01 9.9393857e-01 9.9958616e-01 9.9326342e-01 9.3208420e-01\n",
            " 9.6318144e-01 1.4067328e-04 9.9745101e-01 9.9662125e-01 9.8147696e-01\n",
            " 9.9303365e-01 9.9750841e-01 8.1207931e-01 9.9645448e-01 9.9803060e-01\n",
            " 9.9913150e-01 9.7310466e-01 9.9956924e-01 9.9763393e-01 3.0621049e-01\n",
            " 9.1437632e-01 7.0309454e-01 9.9852788e-01 9.6483809e-01 8.9290634e-02\n",
            " 4.7948115e-04 7.2489196e-01 9.9863154e-01 9.8346287e-01 9.9988103e-01\n",
            " 9.9888009e-01 8.6988616e-01 9.9852848e-01 9.8653942e-01 9.9784160e-01\n",
            " 9.9713552e-01 9.9873763e-01 5.2745581e-02 9.8496467e-01 9.4766325e-01\n",
            " 9.5652646e-01 9.9979776e-01 9.9571228e-01 9.9209410e-01 9.9840987e-01\n",
            " 9.9147207e-01 9.9866414e-01 3.5805595e-01 1.7563419e-01 9.9328059e-01\n",
            " 9.6297854e-01 9.9560553e-01 8.2649933e-03 1.6817436e-01 9.9302906e-01\n",
            " 9.8912549e-01 8.4750885e-01 9.3443793e-01 9.7538108e-01 7.3162782e-01\n",
            " 8.9363098e-01 9.7391880e-01 9.9787307e-01 2.6119247e-03 6.6574371e-01\n",
            " 9.9506325e-01 9.9124771e-01 9.9592906e-01 9.9034202e-01 9.9559158e-01\n",
            " 9.9920875e-01 9.7577775e-01 9.9021965e-01 8.3854884e-01 9.9562520e-01\n",
            " 8.9726418e-01 1.7702854e-03 8.0030328e-01 9.9848193e-01 9.9265349e-01\n",
            " 9.9516159e-01 9.8052245e-01 9.8951995e-01 9.9505901e-01 6.2091023e-01\n",
            " 4.5728960e-04 2.6743401e-06 9.9006784e-01 4.3375784e-01 9.9972790e-01\n",
            " 8.7736058e-01 9.9456042e-01 9.9862611e-01 2.2382136e-01 9.9974078e-01\n",
            " 2.3434751e-01 9.9970347e-01 9.3463552e-01 9.1421247e-02 8.0937362e-01\n",
            " 9.9957412e-01 9.9998474e-01 9.9873835e-01 9.9846882e-01 9.9526739e-01\n",
            " 9.9393231e-01 9.9835074e-01 9.9477828e-01 5.8033758e-01 9.9719691e-01\n",
            " 1.9572797e-01 2.1537831e-01 9.9063313e-01 9.9740762e-01 9.9786913e-01\n",
            " 9.9595982e-01 9.9764580e-01 8.9668417e-01 4.3396583e-01 9.9306113e-01\n",
            " 9.9994516e-01 9.9405450e-01 9.9628311e-01 9.9872130e-01 9.9769658e-01\n",
            " 9.9627554e-01 7.4411738e-01 9.9744654e-01 9.9504799e-01 9.9728620e-01\n",
            " 9.7302544e-01 9.9970812e-01 9.9869305e-01 9.9138641e-01 1.1296885e-05\n",
            " 8.9986566e-03 9.9948275e-01 9.9905664e-01 9.9690467e-01]\n",
            "These sentences may contain misinformation: \n",
            "1. When Trump took office, the annual limit was ...\n",
            "2. He withdrew the U. S. from the Trans-Pacific ...\n",
            "3. U. S. troop numbers in Afghanistan increased from ...\n",
            "4. He reached 10,000 false or misleading claims 27 ...\n",
            "5. Later that month, the U. S. House of ...\n"
          ]
        }
      ]
    }
  ]
}