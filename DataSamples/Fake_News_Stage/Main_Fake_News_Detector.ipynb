{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Fake News Detector",
      "provenance": [],
      "mount_file_id": "1DS3NkhS6mw07QQHZBBlO1F7tx_aQh1dA",
      "authorship_tag": "ABX9TyMAWapVMLAXGNFkzQSwmvuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satnavpt/Wiki-Wiki-Editor/blob/master/DataSamples/Fake_News_Stage/Main_Fake_News_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Imports`**"
      ],
      "metadata": {
        "id": "jZucprNInWap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THLV2WS2NEh",
        "outputId": "17da3adf-3540-47ac-876e-f21424d24f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Bidirectional\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Data Preprocessing`**"
      ],
      "metadata": {
        "id": "0xtTlQ-nnQzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Fake News Stage/UTK_train.csv')\n",
        "df = df.dropna()\n",
        "text = df.text.apply(lambda x: (re.sub(r'[^\\w ]+', \"\", x).lower()))\n",
        "#Remove punctuation from the input. Numbers are kept as they may be facts that would help indicate whether a sentence contains fake news. \n",
        "#Implicit preprocessing is also completed via one_hot. \n",
        "label = df.label.tolist()"
      ],
      "metadata": {
        "id": "3vIIeQga2cCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 200000 # Vocabulary size - the number of possible distinct words used in this ML model.\n",
        "#According to the Oxford English Dictionary, there are an estimated 171,146 words currently in use in the English language.\n",
        "#A buffer size has been added as new words / abbreviations / slang may be added to Wikipedia articles as time progresses. \n",
        "#In addition, having a vocab size that's larger than the true vocab size increases the uniqueness of the hashes completed by one_hot, for more accurate results. \n",
        "\n",
        "one_hot_representation = [one_hot(sentences, voc_size) for sentences in text] \n",
        "#Converts each word into a unique numerical represenation as the ML model used only operates on numerics.\n",
        "#It also split words based on white space.\n",
        "\n",
        "sentence_len = 30 \n",
        "#The average sentence size in English is 15 - 20 words, so this is a conservative number to limit the amount of information loss from longer senetences whilst also\n",
        "#ensuring that excessive padding isn't applied to each sentence. \n",
        "embedded_sentence = pad_sequences(one_hot_representation, padding = 'post', maxlen = sentence_len)\n",
        "#This padds (adds 0s to) a sentence's one-hot if the sentence is under sentence_len words\n",
        "#and truncates the one-hot of sentences over sentence_len words to ensure that every sentence's representation is the same shape. \n",
        "#This is necessary as LSTM operates on fixed-size data points. \n",
        "#post padding is used so neural network training is efficient. "
      ],
      "metadata": {
        "id": "n_DIqTrN3dLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`LSTM Model`**"
      ],
      "metadata": {
        "id": "kF-BP42kndsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model = Sequential([\n",
        "#A sequential model allows the model to be created layer-by-layer. Its input is an embedded sentence (of size sentence_len) and its output is a 0 - 1 float. \n",
        "                    Embedding(input_dim = (voc_size + 1), output_dim = 100, input_length = sentence_len, mask_zero = True),\n",
        "#Create a 2D vector containing an embedding vector of size 100 for each word's one-hot.\n",
        "#Embedding vector -  Encodes the meaning of a word such that words that are closer together in the learned vector space are expected to be simmilar in meaning.\n",
        "#(voc_size + 1) as the padding value 0 is masked out.\n",
        "                    Dropout(0.1, noise_shape = None, seed = None),\n",
        "#Randomly set input units to 0 with a frequency of 0.1 and recale up the rest such that the sum over all inputs is unchanged. This helps prevent overfitting. \n",
        "                    MaxPooling1D(pool_size = 3, strides = 3, padding = 'same', data_format = 'channels_last'),\n",
        "#Iterates over the inputs and takes the highest value, which compresses the feature space whilst retaining the important features. \n",
        "                    Bidirectional(LSTM(100, activation = 'tanh', use_bias = 'true', kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', bias_initializer = 'zeros',\n",
        "                                       unit_forget_bias = True), merge_mode = 'concat'),\n",
        "#LSTM is a RNN that's effective in making predictions for long sequences of data such as sentences as it uses a memory cell to withhold past infromation for a longer time.\n",
        "#tanh is used as it's second derivative can sustain for a long range before going to zero, which helps to overcome the vanishing gradient problem.                       \n",
        "                    Dropout(0.1, noise_shape = None, seed = None),\n",
        "                    Dense(1, activation = 'sigmoid', use_bias = True, kernel_initializer = 'glorot_uniform')\n",
        "#Dense feeds all outputs from the previous layer to all of its neurons, with each neuron providing one output (a misinformation prediction) via matrix-vector multiplication. \n",
        "                  ])\n",
        "misinformation_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "print(misinformation_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_EOmcC74DRL",
        "outputId": "93ffa4fa-ab0b-4055-d4d1-07f08b30373e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 30, 100)           20000100  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 100)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 100)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 200)              160800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,161,101\n",
            "Trainable params: 20,161,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_valid, label_train, label_valid = train_test_split(embedded_sentence, df['label'], test_size = 0.2, random_state = 42)\n",
        "#random_state is used for reproducible output across multiple function calls to allow the model to be fine_tuned"
      ],
      "metadata": {
        "id": "Q8qm75Uo5W31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model.fit(data_train, label_train, epochs = 3)"
      ],
      "metadata": {
        "id": "Kr3b2Pho5kFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd2404f-b428-423f-e2b5-05c60256a6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "458/458 [==============================] - 12s 17ms/step - loss: 0.3728 - acc: 0.8134\n",
            "Epoch 2/3\n",
            "458/458 [==============================] - 8s 17ms/step - loss: 0.1220 - acc: 0.9537\n",
            "Epoch 3/3\n",
            "458/458 [==============================] - 8s 17ms/step - loss: 0.0248 - acc: 0.9918\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2999714a50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misinformation_model.save('A_misinformation_model_LSTM.h5') #Creates a HDF5 file for the model. \n",
        "with open(\"A_one_hot_encoder\", \"wb\") as f: \n",
        "    pickle.dump(one_hot, f)"
      ],
      "metadata": {
        "id": "6HBfL52PTNLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Model Evaluation & Testing`**"
      ],
      "metadata": {
        "id": "axdkzLlTTBFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = (misinformation_model.predict(data_valid) >= 0.5).astype(int)\n",
        "accuracy_score(label_valid, test_pred, normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgA3LH1RYr5w",
        "outputId": "ca6a05d6-1fac-4c44-b181-fe3bbeed66cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8640962537599125"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_data = pd.read_csv('UTK_test.csv')\n",
        "df_test_label = pd.read_csv('UTK_submit.csv')\n",
        "df_test = pd.merge(df_test_data, df_test_label)\n",
        "df_test = df_test.dropna()\n",
        "test_text = df_test.text.apply(lambda x: (re.sub(r'[^\\w ]+', \"\", x).lower()))\n",
        "test_one_hot_representation = [one_hot(sentences, voc_size) for sentences in test_text] \n",
        "test_embedded_sentence = pad_sequences(test_one_hot_representation, padding = 'post', maxlen = sentence_len)\n",
        "test_label = df_test.label.tolist()\n",
        "test_pred = (misinformation_model.predict(test_embedded_sentence) >= 0.5).astype(int)\n",
        "accuracy_score(test_label, test_pred, normalize = True)"
      ],
      "metadata": {
        "id": "QnZGTKdf9inM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}